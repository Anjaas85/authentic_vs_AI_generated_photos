{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "siALwsf1eM_M",
        "outputId": "5ef625ad-587d-452c-acef-723e47b96762"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-173d942c-7436-4424-adae-c1ceac720e79\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-173d942c-7436-4424-adae-c1ceac720e79\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving id_rsa to id_rsa\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.ssh\n",
        "!mv id_rsa ~/.ssh/\n",
        "!chmod 600 ~/.ssh/id_rsa"
      ],
      "metadata": {
        "id": "vVcytbxuzuUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n"
      ],
      "metadata": {
        "id": "QPebBY2Mzw3X",
        "outputId": "20b114d2-130c-49b2-aa68-73b593d7edbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-2736fb4be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh -T git@github.com\n"
      ],
      "metadata": {
        "id": "qEXoJkomzzDG",
        "outputId": "4f1c5df4-9d43-454e-c938-1cde2345bf08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi muradhuseynov1! You've successfully authenticated, but GitHub does not provide shell access.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin git@github.com:Anjaas85/authentic_vs_AI_generated_photos.git\n"
      ],
      "metadata": {
        "id": "1L2OGzF6z1aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Anjaas85/authentic_vs_AI_generated_photos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBhKJIMRecEV",
        "outputId": "fd6c6469-af8d-4ee2-fb8e-2bbf943548a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'authentic_vs_AI_generated_photos'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 45 (delta 2), reused 11 (delta 0), pack-reused 30 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45/45), 161.00 MiB | 13.56 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd authentic_vs_AI_generated_photos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSXZQ1NoejPs",
        "outputId": "d17c6e78-27cf-46a9-bdfe-cf9777557a2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/authentic_vs_AI_generated_photos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch regFlipCheckout.pth"
      ],
      "metadata": {
        "id": "Z3sB1GbfqRmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout regFlipCheckout.pth"
      ],
      "metadata": {
        "id": "5X2JZkWqqWWs",
        "outputId": "aad1e2dd-325d-450c-ace4-d01c5b53d00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'regFlipCheckout.pth' set up to track remote branch 'regFlipCheckout.pth' from 'origin'.\n",
            "Switched to a new branch 'regFlipCheckout.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zws0ilmepos",
        "outputId": "3f73cce4-735b-4cbd-9cb3-f023329c33ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Step 1: Define paths\n",
        "data_root = \"./data\"\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "val_dir = os.path.join(data_root, \"val\")\n",
        "class_dirs = [\"class_0\", \"class_1\"]\n",
        "\n",
        "# Step 2: Create folder structure\n",
        "for directory in [train_dir, val_dir]:\n",
        "    for class_dir in class_dirs:\n",
        "        os.makedirs(os.path.join(directory, class_dir), exist_ok=True)\n",
        "\n",
        "# Step 3: Download CIFAR10 dataset\n",
        "cifar10 = CIFAR10(root=\"./\", download=True)\n",
        "data, labels = cifar10.data, cifar10.targets\n",
        "\n",
        "# Step 4: Simulate CIFAKE10 (first 5 classes as \"authentic\", next 5 as \"AI-generated\")\n",
        "labels = [0 if label < 5 else 1 for label in labels]\n",
        "\n",
        "# Step 5: Subset the data to only 20,000 samples (10,000 per class)\n",
        "class_0_indices = np.where(np.array(labels) == 0)[0][:10000]\n",
        "class_1_indices = np.where(np.array(labels) == 1)[0][:10000]\n",
        "\n",
        "# Combine the indices and shuffle them\n",
        "subset_indices = np.concatenate([class_0_indices, class_1_indices])\n",
        "np.random.shuffle(subset_indices)\n",
        "\n",
        "# Subset the data\n",
        "data_subset = data[subset_indices]\n",
        "labels_subset = np.array(labels)[subset_indices]\n",
        "\n",
        "# Step 6: Split the data into train and validation sets (80% train, 20% validation)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(\n",
        "    data_subset, labels_subset, test_size=0.2, random_state=42, stratify=labels_subset\n",
        ")\n",
        "\n",
        "# Helper function to save images\n",
        "def save_images(images, labels, save_dir):\n",
        "    for idx, (image, label) in enumerate(zip(images, labels)):\n",
        "        class_folder = os.path.join(save_dir, f\"class_{label}\")\n",
        "        img = Image.fromarray(image)\n",
        "        img.save(os.path.join(class_folder, f\"{idx}.png\"))\n",
        "\n",
        "# Step 7: Save images to train and val folders\n",
        "save_images(train_data, train_labels, train_dir)\n",
        "save_images(val_data, val_labels, val_dir)\n",
        "\n",
        "print(\"Subset of CIFAKE10 dataset distributed into train and validation folders.\")\n",
        "\n",
        "# --- Model and Training Setup ---\n",
        "from models.densenet_model import create_densenet\n",
        "from utils.data_loader import create_dataloaders, create_test_loader\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Paths and parameters\n",
        "data_dir = 'data'\n",
        "test_split = 0.2  # Use 20% of CIFAR test set for testing\n",
        "\n",
        "# Load train, validation, and test data\n",
        "dataloaders = create_dataloaders(data_dir, batch_size=32)\n",
        "test_loader = create_test_loader(test_split=test_split, batch_size=32)\n",
        "\n",
        "# Load model\n",
        "model = create_densenet(num_classes=2).to(device)\n",
        "\n",
        "# Weighted loss function\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "# Compute class weights based on training data\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Add weight decay\n",
        "\n",
        "# Use a learning rate scheduler to dynamically reduce the learning rate as the training progresses\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, criterion, optimizer, dataloaders, num_epochs=15, checkpoint_path=\"checkpoints\"):\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    training_metrics = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            training_metrics[f'{phase}_loss'].append(epoch_loss)\n",
        "            training_metrics[f'{phase}_acc'].append(epoch_acc)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Save checkpoint if validation loss improves\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                scheduler.step(epoch_loss) # Update learning rate based on validation loss\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), os.path.join(checkpoint_path, f'best_model_epoch_{epoch + 1}.pth'))\n",
        "                print(f'Checkpoint saved at epoch {epoch + 1}.')\n",
        "\n",
        "    return model, training_metrics\n",
        "\n",
        "# Train the model\n",
        "trained_model, training_metrics = train_model(model, criterion, optimizer, dataloaders, num_epochs=10)\n",
        "\n",
        "# Save the model\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "torch.save(trained_model.state_dict(), 'checkpoints/regFlipSmallerCheckout.pth')\n",
        "print(\"Model trained and saved!\")\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "# Save metrics\n",
        "os.makedirs('metrics', exist_ok=True)\n",
        "metrics_file = 'metrics/regFlipSmaller_metrics.txt'\n",
        "with open(metrics_file, 'w') as f:\n",
        "    f.write(\"Epoch-wise metrics:\\n\")\n",
        "    for epoch in range(10):\n",
        "        f.write(f\"Epoch {epoch+1}: Train Loss = {training_metrics['train_loss'][epoch]:.4f}, \"\n",
        "                f\"Train Accuracy = {training_metrics['train_acc'][epoch]:.4f}, \"\n",
        "                f\"Val Loss = {training_metrics['val_loss'][epoch]:.4f}, \"\n",
        "                f\"Val Accuracy = {training_metrics['val_acc'][epoch]:.4f}\\n\")\n",
        "\n",
        "# Validation set evaluation\n",
        "print(\"Final Evaluation:\")\n",
        "print(\"Validation Set:\")\n",
        "with open(metrics_file, 'a') as f:\n",
        "    f.write(\"\\nFinal Evaluation:\\nValidation Set:\\n\")\n",
        "evaluate_model(trained_model, dataloaders['val'], device)\n",
        "\n",
        "print(\"Test Set:\")\n",
        "with open(metrics_file, 'a') as f:\n",
        "    f.write(\"\\nTest Set:\\n\")\n",
        "evaluate_model(trained_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7WxjQNkie3nM",
        "outputId": "e5dadc1b-549b-4bc9-dbb9-6d0d20ea73b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Subset of CIFAKE10 dataset distributed into train and validation folders.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6769 Acc: 0.5839\n",
            "val Loss: 0.6728 Acc: 0.6110\n",
            "Checkpoint saved at epoch 1.\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.6584 Acc: 0.6117\n",
            "val Loss: 0.6531 Acc: 0.6122\n",
            "Checkpoint saved at epoch 2.\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.6515 Acc: 0.6182\n",
            "val Loss: 0.6501 Acc: 0.6232\n",
            "Checkpoint saved at epoch 3.\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.6374 Acc: 0.6404\n",
            "val Loss: 0.6219 Acc: 0.6600\n",
            "Checkpoint saved at epoch 4.\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c31080921a05>\u001b[0m in \u001b[0;36m<cell line: 151>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c31080921a05>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, num_epochs, checkpoint_path)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"huseynovmurad2002@gmail.com\"\n",
        "!git config --global user.name \"Murad Hüseynov\""
      ],
      "metadata": {
        "id": "PMD0MWQB2cIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"regFlipCheckout.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUK1zJ143iEc",
        "outputId": "4d11847e-a339-4360-f51f-1e26ef2443a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[regFlipCheckout.pth 82335fd] regFlipCheckout.pth\n",
            " 2 files changed, 16 insertions(+)\n",
            " create mode 100644 checkpoints/regFlipSmallerCheckout.pth\n",
            " create mode 100644 metrics/regFlipSmaller_metrics.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add two_class_classification.ipynb"
      ],
      "metadata": {
        "id": "A-tmZZZt3xVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --soft HEAD~1\n"
      ],
      "metadata": {
        "id": "mQuEpHpQ3ylB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset"
      ],
      "metadata": {
        "id": "tiu7bEMb7qRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpuhDNMT5VYW",
        "outputId": "bf84d54d-3b7a-402e-8b2a-48aa32b9def3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mcommit 82335fd028e06d4d6df72a4a5f8e422b0bab444f\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mregFlipCheckout.pth\u001b[m\u001b[33m)\u001b[m\n",
            "Author: Murad Hüseynov <huseynovmurad2002@gmail.com>\n",
            "Date:   Wed Dec 4 22:30:27 2024 +0000\n",
            "\n",
            "    regFlipCheckout.pth\n",
            "\n",
            "\u001b[33mcommit 1f81eee08116e6a58e5d2b7e5a64a6814f19e5d2\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/HEAD\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
            "Author: Anja Stanic <anja.stanic2001@gmail.com>\n",
            "Date:   Tue Dec 3 14:36:27 2024 +0000\n",
            "\n",
            "    Result of inital training for val and test\n",
            "\n",
            "\u001b[33mcommit ba1115b84a1f6e4732d0d44ebd00d568cda6f3c7\u001b[m\n",
            "Author: Murad Huseynov <huseynovmurad2002@gmail.com>\n",
            "Date:   Mon Dec 2 17:34:36 2024 +0100\n",
            "\n",
            "    initial model training\n",
            "\n",
            "\u001b[33mcommit 96412c460115b73d7d2bd4c503ad405c60a1bb36\u001b[m\n",
            "Author: Murad Huseynov <huseynovmurad2002@gmail.com>\n",
            "Date:   Mon Dec 2 14:39:13 2024 +0100\n",
            "\n",
            "    initial folder structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add two_class_classification.ipynb"
      ],
      "metadata": {
        "id": "0Ip3Rs195Zle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add checkpoints/densenet_ai_vs_authentic.pth"
      ],
      "metadata": {
        "id": "gQcWaSMw5lMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add utils/data_loader.py\n",
        "!git add utils/evaluation.py\n",
        "!git add models/densenet_model.py"
      ],
      "metadata": {
        "id": "hafazU6B6DER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wG2Jd4t7d5F",
        "outputId": "61b4d228-eab2-4519-cd12-57a9093abc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch regFlipCheckout.pth\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mcifar-10-batches-py/\u001b[m\n",
            "\t\u001b[31mcifar-10-python.tar.gz\u001b[m\n",
            "\t\u001b[31mdata/train/class_0/\u001b[m\n",
            "\t\u001b[31mdata/train/class_1/\u001b[m\n",
            "\t\u001b[31mdata/val/class_0/\u001b[m\n",
            "\t\u001b[31mdata/val/class_1/\u001b[m\n",
            "\t\u001b[31mmodels/__pycache__/\u001b[m\n",
            "\t\u001b[31mutils/__pycache__/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Result of inital training for val and test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYQMP6ae6lDc",
        "outputId": "22b09805-9bad-4055-d0e4-286ea53daa14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 7d673d2d] Result of inital training for val and test\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 checkpoints/densenet_ai_vs_authentic.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin regFlipCheckout.pth"
      ],
      "metadata": {
        "id": "DrlvvZcN7-rD",
        "outputId": "bd036a2c-e47a-4ecb-ef75-4b029969199c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 8, done.\n",
            "Counting objects:  12% (1/8)\rCounting objects:  25% (2/8)\rCounting objects:  37% (3/8)\rCounting objects:  50% (4/8)\rCounting objects:  62% (5/8)\rCounting objects:  75% (6/8)\rCounting objects:  87% (7/8)\rCounting objects: 100% (8/8)\rCounting objects: 100% (8/8), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 25.16 MiB | 2.13 MiB/s, done.\n",
            "Total 6 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "remote: \n",
            "remote: Create a pull request for 'regFlipCheckout.pth' on GitHub by visiting:\u001b[K\n",
            "remote:      https://github.com/Anjaas85/authentic_vs_AI_generated_photos/pull/new/regFlipCheckout.pth\u001b[K\n",
            "remote: \n",
            "To github.com:Anjaas85/authentic_vs_AI_generated_photos.git\n",
            " * [new branch]      regFlipCheckout.pth -> regFlipCheckout.pth\n"
          ]
        }
      ]
    }
  ]
}